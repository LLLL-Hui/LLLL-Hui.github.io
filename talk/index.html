<!DOCTYPE html>
<html lang="ja">

<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">


<meta name="author" content="Han Bao">



<meta name="description" content="Talks Upcoming talks 2022/09/20 Hakubi Seminar (Kyoto University), Japan. Loss function perspective of machine learning: What does a machine learn? Past workshop talks (non-refereed) Nakamura, S., Bao, H., &amp; Sugiyama, M. Robust Computation of Optimal Transport by &beta;-potential Regularization. IEICE Technical Report 122:8-14, 2022. Presented at 45th Information-Based Induction Sciences and Machine Learning Technical Committee (IBISML045), online, Mar. 08-09, 2022. [link] Bao, H. &amp; Sugiyama, M. Fenchel-Young Losses with Skewed">



<link rel="icon" href="/favicon.ico">



<meta name="keywords" content=" computer science  machine learning  statistics ">




<script>
  
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\[\[', '\]\]']],
      processEscapes: true,
      processEnvironments: true,
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    }
  };
</script>

<script async defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script"></script>




<link rel="canonical" href="https://hermite.jp/talk/">




<title>Talk - Han Bao</title>



<link media="screen" rel="stylesheet" href='https://hermite.jp/css/common.css'>
<link media="screen" rel="stylesheet" href='https://hermite.jp/css/content.css'>
<link media="screen" rel="stylesheet" href='https://hermite.jp/css/highlight.css'>

  <link rel="stylesheet" href='https://hermite.jp/css/single.css'>
</head>

<body>
  <div id="wrapper">
    <header id="header">
  <h1>
    <a href="https://hermite.jp/">Han Bao</a>
  </h1>

  <nav>
    
    <span class="nav-bar-item">
      <a class="link" href="/publication/">Publication</a>
    </span>
    
    <span class="nav-bar-item">
      <a class="link" href="/talk/">Talk</a>
    </span>
    
    <span class="nav-bar-item">
      <a class="link" href="/misc/">Misc</a>
    </span>
    
    <span class="nav-bar-item">
      <a class="link" href="/post/">Post</a>
    </span>
    
  </nav>
</header>

    <main id="main" class="post">
      
      
      <div class="content">
        <h2 id="talks">Talks</h2>
<h3 id="upcoming-talks">Upcoming talks</h3>
<ul>
  <li>2022/09/20 Hakubi Seminar (Kyoto University), Japan.<br /><i>Loss function perspective of machine learning:  What does a machine learn?</i></li>
</ul>
<hr />
<h3 id="past-workshop-talks-non-refereed">Past workshop talks (non-refereed)</h3>
<ol reversed="reversed">
  <li>Nakamura, S., <span class="stress-author">Bao, H.</span>, &amp; Sugiyama, M.<br />Robust Computation of Optimal Transport by &beta;-potential Regularization.<br /><i>IEICE Technical Report</i> 122:8-14, 2022.<br />Presented at <i><a href="http://ibisml.org/ibisml045">45th Information-Based Induction Sciences and Machine Learning Technical Committee (IBISML045)</a></i>, online, Mar. 08-09, 2022.<br />[<a href="https://www.ieice.org/ken/paper/20220308bCJU/eng/">link</a>]</li>
  <li><span class="stress-author">Bao, H.</span> &amp; Sugiyama, M.<br />Fenchel-Young Losses with Skewed Entropies.<br />Presented at <i><a href="http://ibisml.org/ibis2021/">24th Information-Based Induction Sciences Workshop (IBIS2021)</a></i>, Online, Nov. 10-13, 2021.</li>
  <li><span class="stress-author">Bao, H.</span>, Scott, C., &amp; Sugiyama, M.<br />Calibrated Surrogate Losses for Adversarially Robust Classification.<br />Presented at <i><a href="http://ibisml.org/ibis2020/">23rd Information-Based Induction Sciences Workshop (IBIS2020)</a></i>, Online, Nov. 23-26, 2020.<br /><span class="stress-note">The winner of the best presentation award.</span></li>
  <li><span class="stress-author">Bao, H.</span> &amp; Sugiyama, M.<br />Calibrated Surrogate Maximization of Linear-fractional Utility in Binary Classification.<br /><i>IEICE Technical Report</i> 119:71-78, 2020.<br />Presented at <i><a href="http://ibisml.org/ibisml039">39th Information-Based Induction Sciences and Machine Learning Technical Committee (IBISML039)</a></i>, Kyoto, Japan, Mar. 10-11, 2020.<br />[<a href="https://www.ieice.org/ken/paper/20200311G1V8/eng/">link</a>]</li>
  <li><span class="stress-author">Bao, H.</span> &amp; Sugiyama, M.<br />Calibrated Surrogate Maximization of Linear-fractional Utility in Binary Classification.<br />Presented at <i><a href="http://ibisml.org/ibis2019/">22nd Information-Based Induction Sciences Workshop (IBIS2019)</a></i>, Nagoya, Japan, Nov. 20-23, 2019.<br /><span class="stress-note">The winner of the student presentation award.</span></li>
  <li>Shimada, T., <span class="stress-author">Bao, H.</span>, Sato, I., &amp; Sugiyama, M.<br />Classification from Pairwise Similarities/Dissimilarities and Unlabeled Data via Empirical Risk Minimization.<br />Presented at <i><a href="http://ibisml.org/ibis2019/">22nd Information-Based Induction Sciences Workshop (IBIS2019)</a></i>, Nagoya, Japan, Nov. 20-23, 2019.</li>
  <li><span class="stress-author">Bao, H.</span> &amp; Sugiyama, M.<br />Calibrated Surrogate Maximization of Linear-fractional Utility in Binary Classification.<br />Presented at <i><a href="https://www.turing.ac.uk/events/uk-japan-robotics-and-ai-research-collaboration-workshops">UK-Japan Robotics and AI Research Collaboration Workshops</a></i>, Edinburgh, UK, Sep. 17-18, 2019.</li>
  <li><span class="stress-author">Bao, H.</span> &amp; Sugiyama, M.<br />Calibrated Surrogate Maximization of Linear-fractional Utility in Binary Classification.<br />Presented at <i><a href="http://www.redaktion.tu-berlin.de/fileadmin/fg131/dima-feed/agenda.pdf">Joint Workshop of BBDC, BZML, and RIKEN AIP</a></i>, Berlin, Germany, Sep. 9-10, 2019.</li>
  <li>Shimada, T., <span class="stress-author">Bao, H.</span>, Sato, I., &amp; Sugiyama, M.<br />Classification from Pairwise Similarities/Dissimilarities and Unlabeled Data via Empirical Risk Minimization.<br />Presented at <i><a href="https://www.airc.aist.go.jp/snl/snl2019.html">3rd International Workshop on Symbolic-Neural Learning (SNL2019)</a></i>, Tokyo, Japan, Jul. 11-12, 2019.</li>
  <li><span class="stress-author">Bao, H.</span>, Niu, G., &amp; Sugiyama, M.<br />Classification from Pairwise Similarity and Unlabeled Data.<br />Presented at <i><a href="https://polarified.wixsite.com/jiml2018">1st Japan-Israel Machine Learning Meeting (JIML-2018)</a></i>, Tel-Aviv, Israel, Nov. 19-20, 2018.<br /><span class="stress-note">The winner of the best poster award.</span><br />[<a href="/posters/201811_JIML.pdf">poster</a>]</li>
  <li>Kuroki, S., Charoenphakdee, N., <span class="stress-author">Bao, H.</span>, Honda, J., Sato, I., &amp; Sugiyama, M.<br />Unsupervised Domain Adaptation Based on Distance between Distributions Using Source-domain Labels.<br />Presented at <i><a href="http://ibisml.org/ibis2018/">21st Information-Based Induction Sciences Workshop (IBIS2018)</a></i>, Sapporo, Japan, Nov. 4-7, 2018.</li>
  <li><span class="stress-author">Bao, H.</span>, Sakai, T., Sugiyama, M., &amp; Sato, I.<br />Risk Minimization Framework for Multiple Instance Learning from Positive and Unlabeled Bags. <br />Presented at <i><a href="https://www.ttic.edu/SNL2017/">1st International Workshop on Symbolic-Neural Learning (SNL2017)</a></i>, Nagoya, Japan, Jul. 7-8, 2017.</li>
  <li><span class="stress-author">Bao, H.</span>, Sakai, T., Sato, I., &amp; Sugiyama, M.<br />Risk Minimization Framework for Multiple Instance Learning from Positive and Unlabeled Bags.<br /><i>IEICE Technical Report</i> 117:55-62, 2017.<br />Presented at <i><a href="http://ibisml.org/ibisml029">29th Information-Based Induction Sciences and Machine Learning Technical Committee (IBISML029)</a></i>, Okinawa, Japan, Jun. 23-25, 2017.<br />[<a href="https://www.ieice.org/ken/paper/20170624ibV6/eng/">link</a>]</li>
  <li><span class="stress-author">Bao, H.</span>, Usui, T., &amp; Matsuura, K.<br />Improving Optimization Level Estimation of Malware by Feature Selection.<br />Presented at <i><a href="https://www.iwsec.org/scis/2015/">32nd Symposium on Cryptography and Information Security (SCIS2015)</a></i>, Kokura, Japan, Jan. 20-23, 2015.</li>
</ol>
<hr />
<h3 id="past-invited-talks">Past invited talks</h3>
<ol reversed="reversed">
  <li>2022/09/09 電子情報通信学会ソサエティ大会（大会企画セッション「データサイエンスと情報理論」），オンライン．<br /><i>学習基準と評価基準の差を探る．(in Japanese)</i><br />[<a href="https://www.ieice-taikai.jp/2022society/jpn/">link</a>]</li>
  <li>2022/07/26 Kyoto Machine Learning Workshop (at Kyoto University), Japan.<br /><i>Reliable and Transferrable Machine Learning via Loss Function Perspective.</i>
  <li>2022/03/16 Seminar Talk at <a href="http://kmlab.iis.u-tokyo.ac.jp/index.html">Matsuura Lab &mdash; The University of Tokyo</a>, Japan.<br /><i>Excess Risk Transfer and Learning Problem Reduction towards Reliable Machine Learning. (in Japanese)</i></li>
  <li>2022/03/10 日本応用数理学会 若手の会 <a href="http://wakate.jsiam.org/">第7回学生研究発表会</a>，オンライン．<br /><i>学習基準と評価基準の差を探る．(in Japanese)</i></li>
  <li>2021/09/29 人工知能学会 <a href="https://sig-fpai.org/past/fpai117_cfp.html">第117回人工知能基本問題研究会(SIG-FPAI)</a>，オンライン．<br /><i>学習基準と評価基準の差を探る．(in Japanese)</i></li>
  <li>2021/03/26 <a href="https://www.nlp.ecei.tohoku.ac.jp/talk/5141/">Michinoku Communication Science Seminar</a> at <a href="https://www.nlp.ecei.tohoku.ac.jp/">Tohoku NLP Lab &mdash; Tohoku University</a>．<br /><i>Learning from Excess Risk Transfer Perspective. (in Japansese)</i></li>
  <li>2020/12/22 <a href="https://www.toshiba.co.jp/rdc/">東芝研究開発センター</a> シンポジウム．<br /><i>敵対的学習における適合的な損失関数．(in Japanese)</i></li>
  <li>2020/12/15 Talk event: Learning theory of loss functions.<br /><i>Calibrated Surrogate Losses and Robust Learning.</i><br />[<a href="https://c5dc59ed978213830355fc8978.doorkeeper.jp/events/113539">link</a>][<a href="/slides/202012_AIP.pdf">slides</a>]</li>
  <li>2020/09/10 Talk at <a href="https://aip.riken.jp/?lang=en">RIKEN AIP</a>, Tokyo, Japan.<br /><i>Learning Theory Bridges Loss Functions.</i><br />[<a href="https://c5dc59ed978213830355fc8978.doorkeeper.jp/events/110665">link</a>][<a href="/slides/202009_AIP.pdf">slides</a>]</li>
  <li>2020/09/07 ソシオグローバル情報工学研究センター講演会 &mdash; 生産技術研究所，東京．<br /><i>損失関数をつなぐ学習理論．(in Japanese)</i><br />[<a href="/slides/202009_IIS.pdf">slides</a>]</li>
  <li>2020/07/13 Seminar Talk at <a href="http://www.ml.ist.i.kyoto-u.ac.jp/en/">Kashima Lab &mdash; Kyoto University</a>, Kyoto, Japan.<br /><i>Learning Theory Bridges Loss Functions.</i><br />[<a href="/slides/202007_KyotoU.pdf">slides</a>]</li>
  <li>2020/02/07 Seminar Talk at <a href="http://sanmi.cs.illinois.edu/group.html">Professor Sanmi Koyejo's Group &mdash; University of Illinois at Urbana-Champaign</a>, Champaign, IL, USA.<br /><i>Calibrated Surrogate Maximization of Linear-fractional Utility in Binary Classification.</i><br />[<a href="/slides/202002_UIUC.pdf">slides</a>]</li>
  <li>2019/09/23 <a href="https://modal.lille.inria.fr/wikimodal/doku.php?id=seminars">Modal Seminar &mdash; INRIA Lille Nord Europe</a>, Lille, France.<br /><i>Unsupervised Domain Adaptation Based on Source-guided Discrepancy.</i><br />[<a href="/slides/201909_Modal.pdf">slides</a>]</li>
  <li>2019/09/19 <a href="http://web.inf.ed.ac.uk/ipab/events/past-events/ipab-seminar-19-09-19">IPAB Seminar &mdash; The University of Edinburgh</a>, Edinburgh, UK.<br /><i>Calibrated Surrogate Maximization of Linear-fractional Utility in Binary Classification.</i></li>
  <li>2019/09/12 Seminar Talk at <a href="https://team.inria.fr/parietal/">Parietal Team</a> &mdash; INRIA Paris-Saclay</a>, Paris, France.<br /><i>Calibrated Surrogate Maximization of Linear-fractional Utility in Binary Classification.</i></li>
  <li>2019/08/10 <a href="https://www.facebook.com/events/631937413953092/">CLASP! 第9回</a>，東京．<br /><i>スモールデータの機械学習．(in Japanese)</i>．</li>
  <li>2019/08/08 <a href="https://www.s.u-tokyo.ac.jp/ja/event/6367/">東京大学理学部オープンキャンパス2019</a>，東京．<br /><i>人工知能は人間の夢を見るか？ (in Japanese)</i></li>
  <li>2018/10/29 第8回脳型人工知能とその応用に関するミニワークショップ &mdash; ATR，京都．<br /><i>弱教師付きデータを用いた統計的分類．(in Japanese)</i></li>
  <li>2018/08/12 <a href="https://sites.google.com/site/workshop201808/">第3回 統計・機械学習若手シンポジウム</a>，東京．<br /><i>Classification from Pairwise Similarity and Unlabeled Data. (in Japanese)</i></li>
  <li>2018/06/18 <a href="https://ircn.jp/en/archives/7753">Science Salon &mdash; International Research Center for Neurointelligence</a>, Tokyo, Japan.<br /><i>Classification from Pairwise Similarity and Unlabeled Data.</i></li>
  <li>2017/09/19 Seminar Talk at <a href="https://www.di.ens.fr/sierra/">Sierra Team</a> &mdash; INRIA Paris, Paris, France.<br /><i>Multiple Instance Learning with Positive and Unlabeled Data.</i></li>
</ol>

      </div>
      
    </main>
    <footer id="footer">
  <div>
    <span>© Han Bao / Last updated: 2022-09-14</span>
  </div>

  <div class="footnote">
    <span></span>
  </div>
</footer>

  </div>
  

<link media="screen" rel="stylesheet" href="https://hermite.jp/css/main.css" />





</body>

</html>
