<!DOCTYPE html>
<html lang="ja">

<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">


<meta name="author" content="Han Bao">



<meta name="description" content="Publication Books Sugiyama, M., Bao, H., Ishida, T., Lu, N., Sakai, T., & Niu, G.
Machine Learning from Weak Supervision: An Empirical Risk Minimization Approach, MIT Press, Cambridge, MA, USA, 2022.
[link] Journal Articles (refereed) Shimada, T., Bao, H., Sato, I., &amp; Sugiyama, M.
Classification from Pairwise Similarities/Dissimilarities and Unlabeled Data via Empirical Risk Minimization.
Neural Computation 33(5):1234-1268, 2021.
[link][arXiv] Bao, H., Sakai, T., Sato, I., &amp; Sugiyama, M.
Convex Formulation of Multiple Instance Learning from Positive and Unlabeled Bags.">



<link rel="icon" href="/favicon.ico">



<meta name="keywords" content=" computer science  machine learning  statistics ">




<script>
  
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\[\[', '\]\]']],
      processEscapes: true,
      processEnvironments: true,
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    }
  };
</script>

<script async defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script"></script>




<link rel="canonical" href="https://hermite.jp/publication/">




<title>Publication - Han Bao</title>



<link media="screen" rel="stylesheet" href='https://hermite.jp/css/common.css'>
<link media="screen" rel="stylesheet" href='https://hermite.jp/css/content.css'>
<link media="screen" rel="stylesheet" href='https://hermite.jp/css/highlight.css'>

  <link rel="stylesheet" href='https://hermite.jp/css/single.css'>
</head>

<body>
  <div id="wrapper">
    <header id="header">
  <h1>
    <a href="https://hermite.jp/">Han Bao</a>
  </h1>

  <nav>
    
    <span class="nav-bar-item">
      <a class="link" href="/publication/">Publication</a>
    </span>
    
    <span class="nav-bar-item">
      <a class="link" href="/talk/">Talk</a>
    </span>
    
    <span class="nav-bar-item">
      <a class="link" href="/misc/">Misc</a>
    </span>
    
    <span class="nav-bar-item">
      <a class="link" href="/post/">Post</a>
    </span>
    
  </nav>
</header>

    <main id="main" class="post">
      
      
      <div class="content">
        <h2 id="publication">Publication</h2>
<h3 id="books">Books</h3>
<ol reversed="reversed">
    <li>Sugiyama, M., <span class="stress-author">Bao, H.</span>, Ishida, T., Lu, N., Sakai, T., & Niu, G.<br /><i>Machine Learning from Weak Supervision: An Empirical Risk Minimization Approach</i>, MIT Press, Cambridge, MA, USA, 2022.<br />[<a href="https://mitpress.mit.edu/books/machine-learning-weak-supervision">link</a>]</li>
</ol>
<hr />
<h3 id="journal-articles-refereed">Journal Articles (refereed)</h3>
<ol reversed="reversed">
    <li>Shimada, T., <span class="stress-author">Bao, H.</span>, Sato, I., &amp; Sugiyama, M.<br />Classification from Pairwise Similarities/Dissimilarities and Unlabeled Data via Empirical Risk Minimization.<br /><i><a href="https://www.mitpressjournals.org/journal/neco">Neural Computation</a></i> 33(5):1234-1268, 2021.<br />[<a href="https://direct.mit.edu/neco/article/33/5/1234/97483">link</a>][<a href="https://arxiv.org/abs/1904.11717">arXiv</a>]</li>
    <li><span class="stress-author">Bao, H.</span>, Sakai, T., Sato, I., &amp; Sugiyama, M.<br />Convex Formulation of Multiple Instance Learning from Positive and Unlabeled Bags.<br /><i><a href="http://www.elsevier.com/locate/neunet">Neural Networks</a></i> 105:132-141, 2018.<br />[<a href="https://www.sciencedirect.com/science/article/pii/S0893608018301527">link</a>][<a href="https://arxiv.org/abs/1704.06767">arXiv</a>]</li>
</ol>
<hr />
<h3 id="conference-proceedings-refereed">Conference Proceedings (refereed)</h3>
<ol reversed="reversed">
    <li><span class="stress-author">Bao, H.</span>, Nagano, Y., &amp; Nozawa, N.<br />On the Surrogate Gap between Contrastive and Supervised Losses.<br />In <i>Proceedings of <a href="https://icml.cc/Conferences/2022/">39th International Conference on Machine Learning (ICML2022)</a></i>, PMLR 162:1585-1606, Baltimore, MD, USA, Jul. 17-23, 2022.<br />[<a href="https://proceedings.mlr.press/v162/bao22e.html">link</a>][<a href="https://arxiv.org/abs/2110.02501">arXiv</a>][<a href="/posters/202207_ICML.pdf">poster</a>][<a href="https://github.com/nzw0301/gap-contrastive-and-supervised-losses">github</a>] <small>(equal contribution &amp; alphabetical ordering)</small></li>
    <li><span class="stress-author">Bao, H.</span><sup>*</sup>, Shimada, T.<sup>*</sup>, Xu, L., Sato, I., &amp; Sugiyama, M.<br />Pairwise Supervision Can Provably Elicit a Decision Boundary.<br />In <i>Proceedings of <a href="https://aistats.org/aistats2022/">25th International Conference on Artificial Intelligence and Statistics (AISTATS2022)</a></i>, PMLR 151:2618-2640, online, Mar. 28-30, 2022.<br />[<a href="https://proceedings.mlr.press/v151/bao22a.html">link</a>][<a href="https://arxiv.org/abs/2006.06207">arXiv</a>][<a href="/posters/202203_AISTATS.pdf">poster</a>] <small>(* equal contribution)</small></li>
    <li>Dan, S., <span class="stress-author">Bao, H.</span>, &amp; Sugiyama, M.<br />Learning from Noisy Similar and Dissimilar Data.<br />In <i>Proceedings of <a href="https://2021.ecmlpkdd.org/">the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECMLPKDD2021)</a></i>, LNCS 12976:233-249, online, Sep. 13-17, 2021.</i><br />[<a href="https://link.springer.com/chapter/10.1007/978-3-030-86520-7_15">link</a>][<a href="https://arxiv.org/abs/2002.00995">arXiv</a>]</li>
    <li><span class="stress-author">Bao, H.</span> &amp; Sugiyama, M.<br />Fenchel-Young Losses with Skewed Entropies for Class-posterior Probability Estimation.<br />In <i>Proceedings of <a href="https://aistats.org/aistats2021/">24th International Conference on Artificial Intelligence and Statistics (AISTATS2021)</a></i>, PMLR 130:1648-1656, online, Apr. 13-15, 2021.<br />[<a href="http://proceedings.mlr.press/v130/bao21b.html">link</a>][<a href="/posters/202104_AISTATS.pdf">poster</a>][<a href="https://github.com/levelfour/GEV_Fenchel_Young_Loss">github</a>]</li>
    <li>Nordstr&ouml;m, M., <span class="stress-author">Bao, H.</span>, L&ouml;fman, F., Hult, H., Maki, A., &amp; Sugiyama, M.<br />Calibrated Surrogate Maximization of Dice.<br />In <i>Proceedings of <a href="https://www.miccai2020.org/">23rd International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI2020)</a></i>, LNCS 12264:269-278, online, Oct. 4-8, 2020.<br />[<a href="https://link.springer.com/chapter/10.1007/978-3-030-59719-1_27">link</a>]</li>
    <li><span class="stress-author">Bao, H.</span>, Scott, C., &amp; Sugiyama, M.<br />Calibrated Surrogate Losses for Adversarially Robust Classification.<br />In <i>Proceedings of <a href="http://learningtheory.org/colt2020/">33rd Annual Conference on Learning Theory (COLT2020)</a></i>, PMLR 125:408-451, online, Jul. 9-12, 2020.<br />[<a href="http://proceedings.mlr.press/v125/bao20a.html">link</a>][<a href="https://arxiv.org/abs/2005.13748">arXiv <small>(corrigendum)</small></a>][<a href="/slides/202007_COLT.pdf">slides</a>] <small>(arXiv version contains a corrigendum; the definition of calibrated losses is modified)</small></li>
    <li><span class="stress-author">Bao, H.</span> &amp; Sugiyama, M.<br />Calibrated Surrogate Maximization of Linear-fractional Utility in Binary Classification.<br />In <i>Proceedings of <a href="https://www.aistats.org/aistats2020/">23rd International Conference on Artificial Intelligence and Statistics (AISTATS2020)</a></i>, PMLR 108:2337-2347, online, Aug. 26-28, 2020.<br />[<a href="http://proceedings.mlr.press/v108/bao20a.html">link</a>][<a href="https://arxiv.org/abs/1905.12511">arXiv</a>][<a href="/slides/202008_AISTATS.pdf">slides</a>]</li>
    <li>Wu, Y.-H., Charoenphakdee, N., <span class="stress-author">Bao, H.</span>, Tangkaratt, V., &amp; Sugiyama, M.<br />Imitation Learning from Imperfect Demonstration.<br />In <i>Proceedings of <a href="https://icml.cc/Conferences/2019">36th International Conference on Machine Learning (ICML2019)</a></i>, PMLR 97:6818-6827, Long Beach, CA, USA, Jun. 9-15, 2019.<br />[<a href="http://proceedings.mlr.press/v97/wu19a.html">link</a>][<a href="https://arxiv.org/abs/1901.09387">arXiv</a>][<a href="/posters/201906_ICML.pdf">poster</a>][<a href="https://github.com/kristery/Imitation-Learning-from-Imperfect-Demonstration">github</a>]</li>
    <li>Kuroki, S., Charoenphakdee, N., <span class="stress-author">Bao, H.</span>, Honda, J., Sato, I., &amp; Sugiyama, M.<br />Unsupervised Domain Adaptation Based on Source-guided Discrepancy.<br />In <i>Proceedings of <a href="https://aaai.org/Conferences/AAAI-19/">33rd AAAI Conference on Artificial Intelligence (AAAI2019)</a></i>, 33 01:4122-4129, Honolulu, HI, USA, Jan. 27-Feb. 1, 2019.<br />[<a href="https://aaai.org/ojs/index.php/AAAI/article/view/4313">link</a>][<a href="https://arxiv.org/abs/1809.03839">arXiv</a>]</li>
    <li><span class="stress-author">Bao, H.</span>, Niu, G., &amp; Sugiyama, M.<br />Classification from Pairwise Similarity and Unlabeled Data.<br />In <i>Proceedings of <a href="https://icml.cc/Conferences/2018/">35th International Conference on Machine Learning (ICML2018)</a></i>, PMLR 80:461-470, Stockholm, Sweden, Jul. 10-15, 2018.<br />[<a href="http://proceedings.mlr.press/v80/bao18a.html">link</a>][<a href="https://arxiv.org/abs/1802.04381">arXiv</a>][<a href="/slides/201807_ICML.pdf">slides</a>][<a href="/posters/201807_ICML.pdf">poster</a>][<a href="https://github.com/levelfour/SU_Classification">github</a>]</li>
</ol>
<hr />
<h3 id="preprints">Preprints</h3>
<ul>
    <li>Yamada, M., Takezawa, Y., Sato, R., <span class="stress-author">Bao, H.</span>, Kozareva, Z., &amp; Ravi, S..<br />Approximating 1-Wasserstein Distance with Trees.<br />[<a href="https://arxiv.org/abs/2206.12116">arXiv</a>]</li>
</ul>

      </div>
      
    </main>
    <footer id="footer">
  <div>
    <span>© Han Bao / Last updated: 2022-09-14</span>
  </div>

  <div class="footnote">
    <span></span>
  </div>
</footer>

  </div>
  

<link media="screen" rel="stylesheet" href="https://hermite.jp/css/main.css" />





</body>

</html>
